tasks:   
  # captioning:
  #   GIT:
  #     framework: huggingface
  #     load_model:
  #       framework: huggingface
  #       model_loading_function: 'transformers.AutoModelForCausalLM.from_pretrained'
  #       parameters_load_function: 
  #         pretrained_model_name_or_path : "microsoft/git-base-vatex"
  #       transformation_function: src.transformations.huggingface_transform
  #       parameters_transformation:
  #         processor_function: transformers.AutoProcessor.from_pretrained
  #         pretrained_model_name_or_path: "microsoft/git-base-vatex" 
  #     export:
  #       csv: yes
  # object_detection:
  #   fasterrcnn_resnet50_fpn_v2:
  #     framework: torch
  #     load_model:
  #       framework: torch
  #       model_loading_function: torchvision.models.detection.fasterrcnn_resnet50_fpn_v2
  #       parameters_load_function:
  #         weights: "FasterRCNN_ResNet50_FPN_V2_Weights.DEFAULT"
  #       transformation_function: 'src.transformations.torch_transform'
  #       parameters_transformation:
  #         weights: FasterRCNN_ResNet50_FPN_V2_Weights.DEFAULT
  #       classes_function: 'src.dataset_labels_mapping.classes_mapping'
  #       parameters_classes:
  #         weights: FasterRCNN_ResNet50_FPN_V2_Weights.DEFAULT
  #     preprocessing:
  #       unsqueeze: false
  #       to_tensor: false
  #       to_list: yes
  #     postprocessing:
  #       - src.postprocessing.threshold
  #       - src.tracker.tracking
  #     threshold_value : 0.75  
  #     export:
  #       video: no
  #       csv: no
  #       hdf5: no
  # semantic_segmentation:
  #   FCN_ResNet101:
  #     load_model:
  #       framework: torch
  #       model_loading_function: torchvision.models.segmentation.fcn_resnet101
  #       parameters_load_function:
  #         weights: FCN_ResNet101_Weights.DEFAULT
  #       transformation_function: 'src.transformations.torch_transform'
  #       parameters_transformation:
  #         weights: FCN_ResNet101_Weights.DEFAULT
  #       classes_function: 'src.dataset_labels_mapping.classes_mapping'
  #       parameters_classes:
  #         weights: FCN_ResNet101_Weights.DEFAULT
  #     preprocessing:
  #       unsqueeze: yes
  #       to_tensor: false
  #       to_list: false
  #     postprocessing:
  #       - src.postprocessing.soft_max
  #     export:
  #       video: yes
  #       resize: 520
  #       csv: no
  #       hdf5: yes
  # keypoints:
  #   KeypointRCNN_ResNet50:
  #     load_model:
  #       framework: torch
  #       model_loading_function: torchvision.models.detection.keypointrcnn_resnet50_fpn
  #       parameters_load_function:
  #         weights: KeypointRCNN_ResNet50_FPN_Weights.DEFAULT
  #       transformation_function: 'src.transformations.torch_transform'
  #       parameters_transformation:
  #         weights: KeypointRCNN_ResNet50_FPN_Weights.DEFAULT
  #       classes_function: 'src.dataset_labels_mapping.classes_mapping'
  #       parameters_classes:
  #         weights: KeypointRCNN_ResNet50_FPN_Weights.DEFAULT
  #     preprocessing:
  #       unsqueeze: false
  #       to_tensor: false
  #       to_list : yes
  #     postprocessing:
  #       - src.postprocessing.threshold
  #       - src.tracker.tracking
  #     threshold_value : 0.75  
  #     export:
  #       video: yes
  #       csv: yes
  # instance_segmentation:
  #   MaskRCNN_ResNet50_FPN:
  #     load_model:
  #       framework: torch
  #       model_loading_function: torchvision.models.detection.maskrcnn_resnet50_fpn
  #       parameters_load_function:
  #         weights: MaskRCNN_ResNet50_FPN_Weights.DEFAULT
  #       transformation_function: 'src.transformations.torch_transform'
  #       parameters_transformation:
  #         weights: MaskRCNN_ResNet50_FPN_Weights.DEFAULT
  #       classes_function: 'src.dataset_labels_mapping.classes_mapping'
  #       parameters_classes:
  #         weights: MaskRCNN_ResNet50_FPN_Weights.DEFAULT
  #     preprocessing:
  #       unsqueeze: false
  #       to_tensor: false
  #       to_list : yes
  #     postprocessing:
  #       - src.postprocessing.threshold
  #       - src.tracker.tracking
  #     threshold_value : 0.75  
  #     export:
  #       video: yes
  #       csv: no
  #       resize: 1080
  # action_detection:
  #   slowfast_r50_detection:
  #     framework: pytorchvideo
  #     load_model:
  #       framework: pytorchvideo
  #       model_loading_function: 'torch.hub.load'
  #       parameters_load_function:
  #         repo_or_dir: 'facebookresearch/pytorchvideo'
  #         model: 'slowfast_r50_detection'
  #         pretrained: True
  #       transformation_function: 'src.transformations.torchhub_transform'
  #       parameters_transformation:
  #         torchhub_model_variant: 'slowfast_r50_detection'
  #         clip_duration: 0.5
  #       classes_function: 'src.dataset_labels_mapping.classes_mapping'
  #       parameters_classes:
  #         dataset: "ava"
  #       clip_duration: 0.7
  #     export:
  #       hdf5: no
  #       video: yes
  # action_classification:
  #   X3D:
  #     load_model:
  #       framework: torchhub
  #       model_loading_function: 'torch.hub.load'         
  #       parameters_load_function:
  #         repo_or_dir: 'facebookresearch/pytorchvideo'
  #         model: 'x3d_s'
  #         pretrained: True
  #       transformation_function: 'src.transformations.torchhub_transform'
  #       parameters_transformation:
  #          torchhub_model_variant: 'x3d_s'
  #          clip_duration: None
  #       classes_function: 'src.dataset_labels_mapping.classes_mapping'
  #       parameters_classes:           
  #         dataset: kinetics400
  #     export:
  #       csv: yes 
  depth_estimation:
    MiDaS:
      load_model:
        framework: torchhub
        model_loading_function: 'torch.hub.load'
        parameters_load_function:
          repo_or_dir: 'intel-isl/MiDaS'
          model: "DPT_Large"
          pretrained: True
        transformation_function: 'src.transformations.torchhub_transform'
        parameters_transformation:
          torchhub_model_variant: 'MiDaS'
          clip_duration: None
        preprocessing:
          unsqueeze: false
          to_tensor: false
          to_list: false
      export:
        video: yes
        csv: no

inputs: /tank/tgn252/test_vid
outputs: /tank/tgn252/metadata_annotations/result
class_paths:
 kinetics400: /tank/tgn252/metadata_annotations/library/kinetics_classnames.json
 ava: /tank/tgn252/metadata_annotations/library/ava_action_list.pbtxt  

